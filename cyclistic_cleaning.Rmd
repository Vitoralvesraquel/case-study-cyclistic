---
title: "Cyclistic Data Cleaning and Preparing"
author: "Vitor Alves Raquel"
date: '2022-06-14'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE}
setwd("/home/vitor/RStudio-projects/case-study-cyclistic")
Sys.setlocale("LC_ALL", "C")
```


```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(janitor)
```

Make a list of the csv files inside the directory with original data.
Apply read_csv function to all files in the list.

```{r message=FALSE}
df_list <- list.files(path = "Data/Original", pattern = ".csv", 
                      full.names = TRUE, recursive = TRUE) %>% 
    lapply(read_csv)
```

Verify if dataframes match.

```{r}
compare_df_cols(df_list, return = "mismatch", strict_description = TRUE)
```


Count total number of rows in the list.

```{r}
sum_rows_list <- sum(sapply(df_list, nrow))
sum_rows_list
```


Combine all data from the list. Compare the number of rows in the list with the
number of rows in the new dataframe to verify that all rows were combined.

```{r}
df <- bind_rows(df_list)
sum_rows_list == nrow(df)

```


Remove list from memory since it will not be used from now on.

```{r}
rm(df_list)
```


View columns data types and first rows.

```{r}
glimpse(df)
```


Check for NAs.

```{r}
colSums(is.na(df))
```


Count unique values for ride_id and compare with number of rows to check for 
duplicates.

```{r}
length(unique(df$ride_id)) == sum_rows_list
```

Remove ride_id column.
```{r}
df$ride_id <- NULL
```


Create columns for trip duration and year/month, day, day of the week, and start hour as integer.


```{r}
df <- df %>% 
    mutate(trip_duration = as.duration(ended_at - started_at),
           month_year = format(started_at, "%Y-%m"),
           day = day(started_at),
           day_of_week = wday(started_at, label = TRUE),
           start_int_hour = as.integer(format(started_at, "%H")))
```


View data summary to check for anything unusual.

```{r}
summary(df)
```

The trip duration column shows some problems. The minimum value is negative and 
maximum is in weeks, which is too big. 
Values smaller than 1 minute will also be disconsidered, since they could 
represent false starts or users trying to re-dock, according to the data 
description at https://ride.divvybikes.com/system-data.
Duration values longer than one day are considered as lost or stolen bikes, 
according to 
https://help.divvybikes.com/hc/en-us/articles/360033484791-What-if-I-keep-a-bike-out-too-long-, and will remain in the dataset for further analysis.

```{r}
df <- df[df$trip_duration > 60,]
summary(df$trip_duration)
```

```{r}
glimpse(df)
```


Remove extra whitespaces from station names.

```{r}
df <- df %>% 
    mutate(start_station_name = str_squish(start_station_name),
           end_station_name = str_squish(end_station_name))
```


check unique values

```{r}
unique(df$rideable_type)
unique(df$member_casual)
```

It is not explained at the data description at the company website what 
docked_bike means in rideable_type. It will remain in the analysis until 
clarified.


compare start and end station names

```{r}
unique_start_station <- sort(unique(df$start_station_name))
unique_end_station <- sort(unique(df$end_station_name))
only_start <- setdiff(unique_start_station, unique_end_station)
```

```{r}
df[df$start_station_name %in% only_start,]
```

```{r}
only_end <- setdiff(unique_end_station, unique_start_station)
```

```{r}
df[df$end_station_name %in% only_end,]
```

The comparison between start and end station showed some issues that should be 
discussed with the people responsible for the database before discarding any 
rows:
- Why some stations only appear at start or end?
- Why some coordinates are rounded to 2 decimal digits? In latitude this is an 
accuracy at around 1 kilometer.
- Every rideable_type in those cases are electric_bike. Does the technical team 
diagnosed any problems in electrical bikes?


```{r}
save(df, file = "Data/df.Rda")
```

```{r}
rm(list = ls())
```


