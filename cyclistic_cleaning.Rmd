---
title: "Cyclistic Data Cleaning"
author: "Vitor Alves Raquel"
date: '2022-06-14'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE}
setwd("/home/vitor/RStudio-projects/case-study-cyclistic")
Sys.setlocale("LC_ALL", "C")
```


```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(janitor)
```

Make a list of the csv files inside the directory with original data.
Apply read_csv function to all files in the list.

```{r message=FALSE}
df_list <- list.files(path = "Data/Original", pattern = ".csv", 
                      full.names = TRUE, recursive = TRUE) %>% 
    lapply(read_csv)
```

Verify if dataframes match.

```{r}
compare_df_cols(df_list, return = "mismatch", strict_description = TRUE)
```



Count total number of rows in the list.

```{r}
sum_rows_list <- sum(sapply(df_list, nrow))
sum_rows_list
```

Combine all data from the list. Compare the number of rows in the list with the
number of rows in the new dataframe to verify that all rows were combined.

```{r}
df <- bind_rows(df_list)
sum_rows_list == nrow(df)

```
Remove list from memory since it will not be used from now on.
```{r}
rm(df_list)
```

View columns data types and first rows.

```{r}
glimpse(df)
```
Check for NAs.

```{r}
colSums(is.na(df))
```
Count unique values for ride_id and compare with number of rows to check for 
duplicates.

```{r}
length(unique(df$ride_id)) == sum_rows_list
```

Create columns for trip duration, month_year, day, weekday.

```{r}
df <- df %>% 
    mutate(trip_duration = as.duration(ended_at - started_at),
           month_year = format(started_at, "%Y-%m"),
           day = day(started_at),
           weekday = wday(started_at, label = TRUE))
unique(df$month_year)
```


View data summary to check for anything unusual.

```{r}
summary(df)
```

The trip duration column shows some problems. The minimum value is negative and 
maximum is in weeks, which is too big. 
Values smaller than 1 minute will also be disconsidered, since they could 
represent false starts or users trying to re-dock, according to the data 
description at https://ride.divvybikes.com/system-data.
Large values must be discussed with the people responsible for the data before 
discarding.

```{r}
df <- df[df$trip_duration > 60,]
summary(df$trip_duration)
```

Remove extra whitespaces from station names.

```{r}
df <- df %>% 
    mutate(start_station_name = str_squish(start_station_name),
           end_station_name = str_squish(end_station_name))
```

check unique values

```{r}
unique(df$rideable_type)
unique(df$member_casual)
```

compare start and end station names

```{r}
unique_start_station <- sort(unique(df$start_station_name))
unique_end_station <- sort(unique(df$end_station_name))
only_start <- setdiff(unique_start_station, unique_end_station)
```

```{r}
df[df$start_station_name %in% only_start,]
```

```{r}
only_end <- setdiff(unique_end_station, unique_start_station)
```

```{r}
df[df$end_station_name %in% only_end,]
```

The comparison between start and end station showed some issues that should be 
discussed with the people responsible for the database before discarding any 
rows:
- Why some stations only appear at start or end?
- Why some coordinates are rounded to 2 decimal digits? In latitude this is an 
accuracy at around 1 kilometer.
- Every rideable_type in those cases are electric_bike. Does the technical team 
diagnosed any problems in electrical bikes?


```{r}
# save(df, file = "Data/df.Rda")
```

```{r}
# rm(df, sum_rows_list)
```


